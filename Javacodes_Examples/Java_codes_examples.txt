HbaseWrkadd.java
import java.io.IOException;

import org.apache.hadoop.conf.Configuration;

import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.HColumnDescriptor;
import org.apache.hadoop.hbase.client.HBaseAdmin;
public class HbaseWrkadd {

        public static void main(String[] args) throws IOException{
                // TODO Auto-generated method stub
                Configuration config = HBaseConfiguration.create();
              @SuppressWarnings("resource")
              HBaseAdmin admin = new HBaseAdmin(config);
                HColumnDescriptor columnDescriptor = new HColumnDescriptor("contactDetails");
                // Adding column family
              admin.addColumn("test", columnDescriptor);
              System.out.println("coloumn added");
            HColumnDescriptor columnDescriptor1 = new HColumnDescriptor("grptests");
            admin.addColumn("test", columnDescriptor1);
              System.out.println("coloumn added");
        }

}
==============================
HbaseWrkcr.java
import java.io.IOException;

import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.HColumnDescriptor;
import org.apache.hadoop.hbase.HTableDescriptor;
import org.apache.hadoop.hbase.client.HBaseAdmin;


import org.apache.hadoop.conf.Configuration;
public class HbaseWrkcr {

        public static void main(String[] args) throws IOException{
                // TODO Auto-generated method stub

              // Instantiating table descriptor class
              HTableDescriptor descriptor = new
              HTableDescriptor("employee123");

              // Adding column families to table descriptor
              descriptor.addFamily(new HColumnDescriptor("personal"));
              descriptor.addFamily(new HColumnDescriptor("professional"));

               {
              //Create a hbaseAdmin
              Configuration config = HBaseConfiguration.create();
              @SuppressWarnings("resource")
                HBaseAdmin admin = new HBaseAdmin(config);

              // Execute the table through admin
              admin.createTable(descriptor);
              System.out.println(" Table created ");
              }}
=======================================
HbaseWrkdel.java
import java.io.IOException;

import org.apache.hadoop.conf.Configuration;

import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.client.HBaseAdmin;
public class HbaseWrkdel {

        public static void main(String[] args) throws IOException{
                // TODO Auto-generated method stub
                Configuration config = HBaseConfiguration.create();
              @SuppressWarnings("resource")
              HBaseAdmin admin = new HBaseAdmin(config);
                // Deleting column family
              admin.deleteColumn("test", "grptests");
              System.out.println("coloumn deleted");
              // Verifying the existance of the table
              boolean bool = admin.tableExists("emp");
              System.out.println( bool);


        }

}
=======================================
HbaseWrkdis.java
        import java.io.IOException;

        import org.apache.hadoop.conf.Configuration;
                import org.apache.hadoop.hbase.HBaseConfiguration;
                import org.apache.hadoop.hbase.HTableDescriptor;
                import org.apache.hadoop.hbase.client.HBaseAdmin;

public class HbaseWrkdis {

        public static void main(String[] args) throws IOException{

        // TODO Auto-generated method stub
    //Create a hbaseAdmin
        Configuration config = HBaseConfiguration.create();
        @SuppressWarnings("resource")
        HBaseAdmin admin = new HBaseAdmin(config);
        Boolean bool = admin.isTableDisabled("emp");
    System.out.println(bool);
    if(!bool){
        admin.disableTable("emp");
        System.out.println("Table disabled");
                              }}}
===================================
HbaseWrkinsrt.java
import java.io.IOException;

import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.client.HTable;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.util.Bytes;


import org.apache.hadoop.conf.Configuration;

public class HbaseWrkinsrt {

        public static void main(String[] args) throws IOException{

                // TODO Auto-generated method stub
                //Create a hbaseAdmin
              Configuration config = HBaseConfiguration.create();

           // Instantiating HTable class
              HTable hTable = new HTable(config, "emp");

              // Instantiating Put class
              // accepts a row name.
              Put p = new Put(Bytes.toBytes("row1"));
           // adding values using add() method
              // accepts column family name, qualifier/row name ,value
              p.add(Bytes.toBytes("personal"),
              Bytes.toBytes("name"),Bytes.toBytes("raju"));

              p.add(Bytes.toBytes("personal"),
              Bytes.toBytes("city"),Bytes.toBytes("hyderabad"));
              p.add(Bytes.toBytes("professional"),Bytes.toBytes("designation"),
              Bytes.toBytes("manager"));

              p.add(Bytes.toBytes("professional"),Bytes.toBytes("salary"),
              Bytes.toBytes("50000"));

              // Saving the put Instance to the HTable.
              hTable.put(p);
              System.out.println("data inserted");

              // closing HTable
              hTable.close();
        }

}
===================================
HbaseWrklis.java
 import java.io.IOException;

        import org.apache.hadoop.conf.Configuration;
                import org.apache.hadoop.hbase.HBaseConfiguration;
                import org.apache.hadoop.hbase.MasterNotRunningException;
                import org.apache.hadoop.hbase.HTableDescriptor;
                import org.apache.hadoop.hbase.client.HBaseAdmin;

public class HbaseWrklis {

        public static void main(String[] args) throws IOException{

        // TODO Auto-generated method stub

                              //Create a hbaseAdmin
                              Configuration config = HBaseConfiguration.create();
                              @SuppressWarnings("resource")
                                  HBaseAdmin admin = new HBaseAdmin(config);
                              HTableDescriptor[] tableDescriptor = admin.listTables();
                              {
                              // printing all the table names.
                              for (int i=0; i<tableDescriptor.length;i++ ){
                                 System.out.println(tableDescriptor[i].getNameAsString());
                              }}}}
===============================================
HbaseWrkread.java
import java.io.IOException;

import org.apache.hadoop.conf.Configuration;

import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.client.Get;
import org.apache.hadoop.hbase.client.HTable;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.util.Bytes;

public class HbaseWrkread {

        public static void main(String[] args) throws IOException{

                // TODO Auto-generated method stub
                //Create a hbaseAdmin
              Configuration config = HBaseConfiguration.create();

           // Instantiating HTable class
              HTable hTable = new HTable(config, "emp");
           // Instantiating Get class
              Get g = new Get(Bytes.toBytes("row1"));

              // Reading the data
              Result result = hTable.get(g);

              // Reading values from Result class object
              byte [] value = result.getValue(Bytes.toBytes("personal"),Bytes.toBytes("name"));

              byte [] value1 = result.getValue(Bytes.toBytes("personal"),Bytes.toBytes("city"));
	      // Printing the values
              String name = Bytes.toString(value);
              String city = Bytes.toString(value1);

              System.out.println("name: " + name + " city: " + city);
        }

}
===================================
HbaseWrkshut.java
import java.io.IOException;

import org.apache.hadoop.conf.Configuration;

import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.client.HBaseAdmin;
public class HbaseWrkshut {

        public static void main(String[] args) throws IOException{
                // TODO Auto-generated method stub
                Configuration config = HBaseConfiguration.create();
              @SuppressWarnings("resource")
              HBaseAdmin admin = new HBaseAdmin(config);
           // Shutting down HBase
              System.out.println("Shutting down hbase");
              admin.shutdown();
        }

}
========================================
HiveDemo.java
package org.test.HiveClient;
//package com.test.hiveclient;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.Statement;


public class HiveDemo {
/*
 * Before running this example we should start the      thrift server
 */
        private static String driverName = "org.apache.hadoop.hive.jdbc.HiveDriver";

        public static void main(String[] args) throws SQLException {
                // TODO Auto-generated method stub
 try {
         Class.forName(driverName);
 } catch (ClassNotFoundException e){
         e.printStackTrace();
         System.exit(1);

 }
 Connection con = DriverManager.getConnection(
                 "jdbc:hive://ec2-52-206-51-90.compute-1.amazonaws.com:10000/default", "", "");
 Statement stmt = con.createStatement();

        String tableName = "newtbl";
        stmt.executeQuery("drop table " + tableName);
 ResultSet res = stmt.executeQuery("create table" + tableName +
                        "(id int, name string, dept string)");
        //show tables
        String sql = "show tables '" + tableName + "'";
        System.out.println("Running: " + sql);
        res = stmt.executeQuery(sql);
                if (res.next()) {
                        System.out.println(res.getString(1));
                        }}}

